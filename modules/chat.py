"""
AI å¯¹è¯æ¨¡å— - ä½¿ç”¨ Antigravity Manager åä»£ï¼ˆGemini åè®®ï¼‰
"""
import logging
import warnings

import config

logger = logging.getLogger(__name__)

# Gemini å®¢æˆ·ç«¯
GENAI_AVAILABLE = False

# æŠ‘åˆ¶å¼ƒç”¨è­¦å‘Šï¼ˆAntigravity Tools å®˜æ–¹ä½¿ç”¨æ­¤åº“ï¼‰
warnings.filterwarnings("ignore", message=".*google.generativeai.*", category=FutureWarning)

try:
    import google.generativeai as genai
    GENAI_AVAILABLE = True
except ImportError:
    logger.warning("google-generativeai åº“æœªå®‰è£…ï¼ŒAI å¯¹è¯åŠŸèƒ½ä¸å¯ç”¨")


def init_client():
    """åˆå§‹åŒ– Gemini å®¢æˆ·ç«¯"""
    if not GENAI_AVAILABLE:
        return False
    
    # ç¡®ä¿ URL ä¸å« /v1 åç¼€ï¼ˆGemini åè®®ä½¿ç”¨ /v1beta/ï¼‰
    base_url = config.ANTIGRAVITY_BASE_URL.rstrip("/")
    if base_url.endswith("/v1"):
        base_url = base_url[:-3]
    
    genai.configure(
        api_key=config.ANTIGRAVITY_API_KEY,
        transport="rest",
        client_options={'api_endpoint': base_url}
    )
    logger.info(f"Gemini å®¢æˆ·ç«¯å·²é…ç½®: {base_url}")
    return True


async def test_connection() -> tuple[bool, str]:
    """æµ‹è¯• API è¿æ¥"""
    if not GENAI_AVAILABLE:
        return False, "âŒ AI åŠŸèƒ½ä¸å¯ç”¨ï¼ˆæœªå®‰è£… google-generativeai åº“ï¼‰"
    
    try:
        model = genai.GenerativeModel(config.DEFAULT_MODEL)
        response = model.generate_content(
            "hi",
            request_options={"timeout": 15}
        )
        return True, f"âœ… API è¿æ¥æˆåŠŸï¼æ¨¡å‹: {config.DEFAULT_MODEL}"
    except Exception as e:
        error_msg = str(e)
        if "503" in error_msg or "unavailable" in error_msg.lower():
            return False, "âŒ API æœåŠ¡ä¸å¯ç”¨ã€‚è¯·ç¡®ä¿ Antigravity Manager æ­£åœ¨è¿è¡Œã€‚"
        elif "connection" in error_msg.lower():
            return False, "âŒ æ— æ³•è¿æ¥åˆ° Antigravity Managerã€‚"
        else:
            return False, f"âŒ API é”™è¯¯: {error_msg[:200]}"


def _convert_history(messages: list[dict]) -> tuple[list[dict], str]:
    """å°† OpenAI æ ¼å¼çš„å†å²è½¬æ¢ä¸º Gemini æ ¼å¼
    
    è¾“å…¥: [{"role": "user", "content": "..."}, {"role": "assistant", "content": "..."}]
    è¾“å‡º: (gemini_history, last_user_message)
    
    Gemini æ ¼å¼: [{"role": "user", "parts": ["..."]}, {"role": "model", "parts": ["..."]}]
    """
    if not messages:
        return [], ""
    
    # æœ€åä¸€æ¡æ¶ˆæ¯æ˜¯å½“å‰ç”¨æˆ·è¾“å…¥
    last_msg = messages[-1]["content"]
    
    # ä¹‹å‰çš„æ¶ˆæ¯ä½œä¸ºå†å²
    history = []
    for msg in messages[:-1]:
        role = "model" if msg["role"] == "assistant" else "user"
        history.append({
            "role": role,
            "parts": [msg["content"]]
        })
    
    return history, last_msg


def chat(messages: list[dict], model: str = None) -> str:
    """å‘é€æ¶ˆæ¯å¹¶è·å–å›å¤"""
    if not GENAI_AVAILABLE:
        raise RuntimeError("AI åŠŸèƒ½ä¸å¯ç”¨ï¼ˆæœªå®‰è£… google-generativeaiï¼‰")
    
    use_model = model or config.DEFAULT_MODEL
    
    try:
        # è½¬æ¢å†å²æ ¼å¼
        history, user_message = _convert_history(messages)
        
        # åˆ›å»ºæ¨¡å‹å’Œå¯¹è¯
        gmodel = genai.GenerativeModel(use_model)
        
        if history:
            # æœ‰å†å²è®°å½•ï¼Œä½¿ç”¨ chat æ¨¡å¼
            conversation = gmodel.start_chat(history=history)
            response = conversation.send_message(
                user_message,
                request_options={"timeout": 30}
            )
        else:
            # æ— å†å²ï¼Œç›´æ¥ç”Ÿæˆ
            response = gmodel.generate_content(
                user_message,
                request_options={"timeout": 30}
            )
        
        # è·å–å›å¤æ–‡æœ¬
        text = response.text
        
        if not text:
            logger.warning(f"AI è¿”å›ç©ºå“åº”, model={use_model}")
            return "æŠ±æ­‰ï¼ŒAI æœªè¿”å›æœ‰æ•ˆå›å¤ï¼Œè¯·é‡è¯•æˆ–æ¢ä¸€ç§æ–¹å¼æé—®ã€‚"
        
        return text
        
    except Exception as e:
        error_msg = str(e)
        if "503" in error_msg or "capacity" in error_msg.lower() or "unavailable" in error_msg.lower():
            raise RuntimeError(f"âš ï¸ æ¨¡å‹ {use_model} æš‚æ—¶ä¸å¯ç”¨ï¼ˆæœåŠ¡å™¨å®¹é‡ä¸è¶³ï¼‰\nè¯·ç”¨ /model åˆ‡æ¢å…¶ä»–æ¨¡å‹")
        elif "block" in error_msg.lower() or "safety" in error_msg.lower():
            return "âš ï¸ è¯¥å›å¤è¢«å®‰å…¨è¿‡æ»¤å™¨æ‹¦æˆªï¼Œè¯·æ¢ä¸€ç§æ–¹å¼æé—®ã€‚"
        raise


def get_model_list() -> str:
    """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
    lines = ["ğŸ¤– **å¯ç”¨æ¨¡å‹åˆ—è¡¨**\n"]
    for i, model in enumerate(config.AVAILABLE_MODELS, 1):
        marker = "âœ“" if model == config.DEFAULT_MODEL else " "
        lines.append(f"{marker} {i}. `{model}`")
    lines.append(f"\nå½“å‰é»˜è®¤: `{config.DEFAULT_MODEL}`")
    lines.append("ä½¿ç”¨ `/model [æ¨¡å‹å]` åˆ‡æ¢æ¨¡å‹")
    return "\n".join(lines)


def is_valid_model(model: str) -> bool:
    """æ£€æŸ¥æ¨¡å‹æ˜¯å¦æœ‰æ•ˆ"""
    return model in config.AVAILABLE_MODELS
